\chapter{Data and elementary statistics}
Now that we are armed with some understanding of how the measureable properties (like brightness and angular size) of a distant object relate to its redshift and the comoving distance, and how these quantities relate back to the cosmological parameters, we can embark on obtaining some data from cosmological measurements.  The data we obtain will always be subject to the uncertainties inherent in our measurement.

In a very generic fashion, we might write that data is a sum of some signal that we are looking for and some noise that muddies our view, something like:
\begin{equation}
  d = s + n.
\end{equation}
As we can often have more than on data point, we can consider these symbols to be vectors or arrays of data, signal, and noise values: they mean $d_i = s_i + n_i$ for each data point indexed with $i$.  It might be more correct to write that the data is some response of our instrument to the signal, plus noise.  In that case, a more proper expression might be
\begin{equation}
  d = R(s) + n.
\end{equation}
where the response is a function of the signal, and again all of these could be vectors of values.

When we make a measurement, the value we get is different every time.  This is what we mean by measurement error or uncertainty.  That means that the noise is a random variable. (Sometimes the signal is too!)  A random variable is a variable that takes a different value each time that you make a measurement, or doing what we might call  ``making a draw'' (like in cards) or ``generating a realization'' (especially if we are simulating the process on a computer).

A measurement that has a noise with a non-zero mean is biased.  A better measurement has a smaller bias and smaller scatter in the noise values (smaller noise variance) than a worse measurement.

\section{Probability distributions}

Any random variable comes from a probability distribution which controls what values are available.  Suppose $X$ is a generic random variable.  The distribution is a function that we integrate to get the probability of certain outcomes for $X$.  For example the probability that $X$ takes a value between $a$ and $b$ would be given by
\begin{equation}
  P(a<X<b) = \int_a^b p(x) dx
\end{equation}
where the probability of the outcome is on the left and the probability distribution for X is the integrand on the right, where little $x$ represents the possible values.  The integral over the whole interval $(-\infty, +\infty)$ is unity: making a draw is going to give us \textit{some} value.

One familiar probability distribution function is the Gaussian distribution,
\begin{equation}
  p(x) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{(x-\mu)^2}{2\sigma^2}   \right),
\end{equation}
which has two parameters, mean $\mu$ and variance $\sigma^2$ (the square of the standard deviation $\sigma$).  It arises very often, whenever there are many independent contributions to a random process, for example, the large number of random Fourier modes contributing to the cosmological density field.

Another common probability distribution is the Poisson distribution, which is the probability for the counting $k$ discrete events or discrete objects if the mean expected number is $\mu$:
\begin{equation}
  P(k) = \frac{\mu^k}{k!}\exp(-\mu).
\end{equation}
It will come up when we are counting photons or stars or galaxies.  Note that the domain here is non-negative integers, so we sum up the probability rather than integrate.

From any probability distribution you can calculate the mean as an integral
\begin{equation}
  \mu = \int dx\,  x  p(x) = \langle x \rangle.
\end{equation}
We introduce the notation $\langle \dots \rangle$ as a shorthand for the integral against the probability distribution of some quantity.  You can also think of this as averaging the quantity over a statistical ensemble\index{ensemble}---an idealized and very large or infinite set of copies of the system that we imagine to probe every possible outcome in the proper proportions.  For the Gaussian distribution this integral does indeed match the $\mu$ parameter from the distribution, as does the corresponding discrete sum over the Poisson distribution.

The mean is called the first moment of the distribution.  Computing the integrals $\langle x^p \rangle$ computes the $p$th moment.  More important here are the central moments $\langle (x-\mu)^p \rangle$ which are computed around the mean of the distribution.

The variance\index{variance} of the distribution is the second central moment, denoted
\begin{equation}
  \sigma^2 = \left\langle (x - \mu)^2 \right\rangle = \left\langle (x - \langle x \rangle)^2 \right\rangle =  \int dx\,  (x-\mu)^2  p(x) 
\end{equation}
The standard deviation\index{standard deviation} is simply the square root of the variance.  A Gaussian distribution is totally described by the mean and variance, and the higher moments can be expressed in terms of them.  The variance for the Poisson distribution is also $\mu$.  General non-Gaussian probability distributions may have information beyond what is in the mean and variance.   The third central moment measures the skewness, how asymmetric the distribution is around the mean.  The fourth central moment, kurtosis, measures how much of a peak or plateau the distrubution has.\footnote{Formal definitions of skewness and kurtosis are normalized by the standard deviation.}  

\section{Statistics}
Statistics are functions of data.  Some of the most important statistics are estimators for the moments or other properties of the distribution.  For example, the average of a data set is the well-known estimator for the mean of the distribution.  For a data set composed of random variables $X_i$.
\begin{equation}
  \bar X = \frac{1}{N_{\rm data}} \sum_i X_i.
\end{equation}
This is a good estimator because it is unbiased: the ensemble average of this estimator is the true mean,
\begin{equation}
  \langle \bar X \rangle = \left\langle \frac{1}{N_{\rm data}} \sum_i X_i \right\rangle =  \frac{1}{N_{\rm data}} \sum_i \left\langle X_i \right\rangle = \frac{N_{\rm data}}{N_{\rm data}} \mu = \mu.
\end{equation}
This, however, is not the only unbiased estimator for the mean.  The weighted average is also unbiased
\begin{equation}
  \bar { X}_w = \frac{ \sum_i w_i X_i}{\sum_i w_i}.
\end{equation}
If in a data set, some of the data points have larger uncertainty than others, it will be advantageous to choose weights that de-emphasize the uncertain points, rather than taking the simple average.  We can evaluate the variance of our statistics.  For example, assuming all the data points are drawn from the same distribution, then the variance of the mean is
\begin{equation}
 {\rm Var}(\bar X) =  \langle (\bar X - \langle \bar X \rangle)^2 \rangle = \frac{\sigma^2}{N_{\rm data}}.
\end{equation}
Thus when we refer to the ``error bar'' or ``uncertainty'' of some averaged quantity, we are referring to the standard deviation, or the square root of this variance.  In a weighted average, we try to choose the weights to minimize the variance of the average.  We call such an estimate optimal.  

We can also construct estimators for the variance.  For example, if we know the mean of a random variable's distribution, then we can construct an unbiased estimate as
\begin{equation}
  \bar \sigma^2 = \frac{1}{N_{\rm data}} \sum_i (X_i - \mu)^2.
\end{equation}
On the other hand, if we don't know the mean and have to estimate it, too, we have the unbiased estimator
\begin{equation}
  \bar \sigma^2 = \frac{1}{N_{\rm data}-1} \sum_i (X_i - \bar X)^2.
\end{equation}
You can also construct weighted average versions of these if need be.

In statistics, it is important to understand the distinction between parameters or properties of a distribution, and statistics that are built from data to estimate those parameters.  This can be confusing because these ideas often have the same name, but please understand that the mean of a probability distribution is a separate concept to the mean of a data set drawn from that distribution.  This first is a parameter; the second is an estimator for that parameter.

\section{Covariances}

Many situations---whenever there is more than one random variable---call for a multivariate probability distribution.  For example, random variables $X$ and $Y$ may be drawn from a joint probability distribution $p(x,y)$. The marginalized distribution integrates out one or more variable from the joint distribution.
\begin{equation}
  p_X(x) = \int dy\, p(x,y)
\end{equation}
If the random variable are independent\index{independent random variables}, then the distribution factors into the marginal distributions, 
\begin{equation}
  p(x,y) = p_X(x) p_Y(y)   \qquad\mbox{(independent variables)},
\end{equation}
but this is not true if the variables are not independent:
\begin{equation}
  p(x,y) \neq p_X(x) p_Y(y)   \qquad\mbox{(correlated, covariant)}.
\end{equation}

The covariance of a pair of random variables is computed similar to the variance, but generalizes it:
\begin{equation}
  {\rm Cov}(X,Y) = \left\langle (X - \langle X \rangle)(Y - \langle Y \rangle) \right\rangle
\end{equation}
Thus, ${\rm Var}(X) = {\rm Cov}(X,X)$.

For a set of variables, the covariance of pairs make a symmetric covariance matrix\index{covariance matrix}, with entries
\begin{equation}
  C_{ij} = {\rm Cov}(X_i, X_j)
\end{equation}
The variance of each $X_i$ lies on the diagonal of the matrix.  If the parameters are independent, the covariance matrix is diagonal.

The multivariate Gaussian distribution for $X$ (now considered as a vector with $k$ entries) is
\begin{equation}
  p(x) = \frac{1}{(2\pi|C|)^{k/2}} \exp\left(-\frac{1}{2} (x-\mu)^\dag C^{-1} (x-\mu) \right) \label{eqn:gaussian}
\end{equation}
where $x$ is the vector of values, $\mu$ is the vector of means, and $C$ is the covariance matrix and $|C|$ is its determinant.

\section{Model fitting}
We'll talk a lot more about methods to fit models to data, but it is helpful to introduce the basic picture.  We again have the simple approximation data as the sum of signal and noise, $d_i = s_i+n_i$, where the noise is a random variable.  Now we introduce a family models for our signal $m_i(\Theta)$, which depends on some vector of parameters $\Theta$.  A good model is one that can represent the signal for some true set of values for its parameters:
\begin{equation}
  s_i=m_i(\Theta = \Theta_0)
\end{equation}
We can construct statistics (functions of data) that evaluate how well any particular model fits to the data.  For $k$ data points, chi-squared is one such statistic, defined for a diagonal noise covariance as:
\begin{equation}
  \chi^2(\Theta) \equiv \sum_{0<i<k} \frac{(d_i - m_i(\Theta))^2}{\sigma_i^2}.
\end{equation}
This statistic accumulates the deviation between the model and the data at each point, squaring to keep the deviation positive, while comparing each point to the expected noise deviation, as recorded by the noise variance.

If we hit upon the correct parameters, we will, on average, yield the smallest possible contribution from each point in the numerator:
\begin{equation}
  \langle (d_i - s_i)^2 \rangle = \langle n_i^2 \rangle = \sigma^2
\end{equation}
so often a good strategy is to minimize the $\chi^2(\Theta)$ statistic function as a function of $\Theta$, yielding best-fit parameters $\bar \Theta_0$ which are an estimate for the true parameters $\Theta_0$.
\begin{equation}
   \chi^2(\Theta) \geq \chi^2_{\rm min} =  \chi^2(\bar \Theta_0)
\end{equation}
Note that, because of the fluctuations due to noise, the true parameters will be a worse fit than the best fit.  That cannot be helped; you only have the data and it includes noise.  Whether the  best-fit parameters $\bar \Theta_0$ are an unbiased estimator for the true parameters must be evaluated on a case-by-case basis.

If we have covariances between the noise values at different data points, then the definition is 
\begin{eqnarray}
  \chi^2(\Theta) \equiv \sum_{0<i,j<k} (d_i - m_i(\Theta))C^{-1}_{ij} (d_i - m_i(\Theta)),
\end{eqnarray}
or,
\begin{eqnarray}
\chi^2  \equiv (d-m)^\dag C^{-1} (d-m),
\end{eqnarray}
in a vector notation.  Otherwise, minimizing $\chi^2$ acts the same.

Minimizing $\chi^2$ is equivalent to maximizing the probability function that data are drawn from a particular model under the assumption that the probability is Gaussian (compare \ref{eqn:gaussian}):
\begin{equation}
  P( d | m(\Theta) ) \propto \exp(-\chi^2/2)
\end{equation}
Because the Gaussian distribution is ubiquitous, this assumption is often justified.  This is the first example of a \textit{maximum likelihood} method.  We will talk much more about likelihoods when we discuss Bayesian statistics in the context of cosmological parameters in Chapter \ref{ch:likelihoods_cosmology}.

Suppose that we have fortunately reproduced the true signal with our model and our probability is Gaussian.  Then the $\chi^2$ statistic is simply the sum of $n_i^2/\sigma_i^2$, or the sum of a $k$ number of unit-variance Gaussian random variables.  In that case, $\chi^2$ as a random variable is drawn from the $\chi^2$-distribution with $k$ degrees of freedom.  The probability distribution function is 
\begin{equation}
  p(x = \chi^2, k) = \frac{1}{2^{k/2} \Gamma(k/2)} x^{(k/2)-1}\exp(-x/2).
\end{equation}
The more parameters we fit, the fewer degrees of freedom there are.  If we fit one parameter, $\chi^2$ will be drawn with $k-1$ degrees of freedom.  If we fit two parameters,  $\chi^2$ will be drawn with $k-2$ degrees of freedom, and so on.
This lets us compute the probability that we measured some range parameter of values by pure chance.  This distribution and its integrals for probability are tabulated in common scientific programming libraries and easy to find.  Sensibly, we cannot fit for more parameters than the number of data point we have.\footnote{Notice that you could perfectly fit a data set with a model that exactly reproduces the data, $m_i = d_i$, yielding $\chi^2 = 0$, but that this model makes no prediction and is useless.}



If we have a bad model, such that the model cannot reproduce the signal for any values of the parameters, all bets are off.  That is why you need to check that the model with the best fit is also a good fit: that the value of $\chi^2$ you end up with or lower could have reasonably been achieved by chance.

If this probability is very close to zero, then that model is probably not a good fit, given the assumption of error bars.  That can be useful to disprove a null hypothesis and discover something: if, for example, if there is low probability that a certain amount of flux was measured by chance from no source, then there must be a source of emission there.  On the other had, if the probability to acheive some value of $\chi$ or lower is unreasonable close to one, this can mean the assumed error bars are over-estimated.



\section*{Exercises}

\begin{enumerate}
\item Show that for a data set $d_i = s + n_i$ with noise that has standard deviation $\sigma_i$, that the weighted-average estimate
  $$
\bar s = \frac{\sum_i w_i d_i}{w_i}
  $$
with inverse-variance weights $w_i = 1/\sigma^2_i$ yields the smallest variance for any weights.  Hint: compute the variance of $\bar s$ for generic weights and then minimize that variance with respect to the weights.

\item $\chi^2$ fit for the amplitude of a quadratic given a data set.  Note that the actual value is different than the fitted value.

\item $\chi^2$ upper limit for a zero-mean data set.
\end{enumerate}
